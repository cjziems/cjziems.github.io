---
---

@article{ziems2023css,
  bibtex_show={true},
  title={Can Large Language Models Transform Computational Social Science?},
  author={Ziems, Caleb and Held, William and Shaikh, Omar and Chen, Jiaao and Zhang, Zhehao and Yang, Diyi},
  journal={arXiv preprint arXiv:2305.03514},
  year={2023},
  month=april,
  pdf={preprints/css_chatgpt.pdf},
  preview={css_chatgpt.png},
  abstract = "Large Language Models (LLMs) like ChatGPT are capable of successfully performing many language processing tasks zero-shot (without the need for training data). If this capacity also applies to the coding of social phenomena like persuasiveness and political ideology, then LLMs could effectively transform Computational Social Science (CSS). This work provides a road map for using LLMs as CSS tools. Towards this end, we contribute a set of prompting best practices and an extensive evaluation pipeline to measure the zero-shot performance of 13 language models on 24 representative CSS benchmarks. On taxonomic labeling tasks (classification), LLMs fail to outperform the best fine-tuned models but still achieve fair levels of agreement with humans. On freeform coding tasks (generation), LLMs produce explanations that often exceed the quality of crowdworkers’ gold references. We conclude that today’s LLMs can radically augment the CSS research pipeline in two ways: (1) serving as zero-shot data annotators on human annotation teams, and (2) bootstrapping challenging creative generation tasks (e.g., explaining the hidden meaning behind text). In summary, LLMs can significantly reduce costs and increase efficiency of social science analysis in partnership with humans.",
  code={https://github.com/SALT-NLP/LLMs_for_CSS},
  selected={true}
}

@article{ziems2023multi,
  bibtex_show={true},
  title={Multi-VALUE: A Framework for Cross-Dialectal English NLP},
  author={Ziems, Caleb and Held, William and Yang, Jingfeng and Dhamala, Jwala and Gupta, Rahul and Yang, Diyi},
  booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  year = "2023",
  month = jul,
  address = "Toronto, Canada",
  publisher = "Association for Computational Linguistics",
  abbr={ACL},
  arxiv={2212.08011},
  altmetric={true},
  website={http://value-nlp.org/},
  preview={multi_value_pipeline.png},
  abstract = "Dialect differences caused by regional, social, and economic factors cause performance discrepancies for many groups of language technology users. Inclusive and equitable language technology must critically be dialect invariant, meaning that performance remains constant over dialectal shifts. Current systems often fall short of this ideal since they are designed and tested on a single dialect: Standard American English (SAE). We introduce a suite of resources for evaluating and achieving English dialect invariance. The resource is called Multi-VALUE, a controllable rule-based translation system spanning 50 English dialects and 189 unique linguistic features. Multi-VALUE maps SAE to synthetic forms of each dialect. First, we use this system to stress tests question answering, machine translation, and semantic parsing. Stress tests reveal significant performance disparities for leading models on non-standard dialects. Second, we use this system as a data augmentation technique to improve the dialect robustness of existing systems. Finally, we partner with native speakers of Chicano and Indian English to release new gold-standard variants of the popular CoQA task. To execute the transformation code, run model checkpoints, and download both synthetic and gold-standard dialectal benchmark datasets, see http://value-nlp.org",
  code={https://github.com/SALT-NLP/multi-value},
  selected={true}
}

@article{ziems2023norm,
  bibtex_show={true},
  title={NormBank: A Knowledge Bank of Situational Social Norms},
  author={Ziems, Caleb, and Dwivedi-Yu, Jane and Wang, Yi-Chia and Halevy, Alon and Yang, Diyi},
  booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
  year = "2023",
  month = jul,
  address = "Toronto, Canada",
  publisher = "Association for Computational Linguistics",
  abbr={ACL},
  arxiv={2305.17008},
  altmetric={true},
  preview={restaurant_roles_1.png},
  abstract = "We present NormBank, a knowledge bank of 155k situational norms. This resource is designed to ground flexible normative reasoning for interactive, assistive, and collaborative AI systems. Unlike prior commonsense resources, NormBank grounds each inference within a multivalent sociocultural frame, which includes the setting (e.g., restaurant), the agents' contingent roles (waiter, customer), their attributes (age, gender), and other physical, social, and cultural constraints (e.g., the temperature or the country of operation). In total, NormBank contains 63k unique constraints from a taxonomy that we introduce and iteratively refine here. Constraints then apply in different combinations to frame social norms. Under these manipulations, norms are non-monotonic - one can cancel an inference by updating its frame even slightly. Still, we find evidence that neural models can help reliably extend the scope and coverage of NormBank. We further demonstrate the utility of this resource with a series of transfer experiments.",
  code={https://github.com/SALT-NLP/normbank},
  selected={true}
}

@article{held2023tada,
  bibtex_show={true},
  title={TADA: Task-Agnostic Dialect Adapters for English},
  author={Held, William and Ziems, Caleb, and Yang, Diyi},
  booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
  year = "2023",
  month = jul,
  address = "Toronto, Canada",
  publisher = "Association for Computational Linguistics",
  abbr={ACL},
  arxiv={2305.16651},
  altmetric={true},
  preview={tada.png},
  abstract = "Large Language Models, the dominant starting point for Natural Language Processing (NLP) applications, fail at a higher rate for speakers of English dialects other than Standard American English (SAE). Prior work addresses this using task-specific data or synthetic data augmentation, both of which require intervention for each dialect and task pair. This poses a scalability issue that prevents the broad adoption of robust dialectal English NLP. We introduce a simple yet effective method for task-agnostic dialect adaptation by aligning non-SAE dialects using adapters and composing them with task-specific adapters from SAE. Task-Agnostic Dialect Adapters (TADA) improve dialectal robustness on 4 dialectal variants of the GLUE benchmark without task-specific supervision.",
  code={https://github.com/Helw150/tada},
}

@article{shaikh2023modeling,
  bibtex_show={true},
  title={Modeling Cross-Cultural Pragmatic Inference with Codenames Duet},
  author={Shaikh, Omar and Ziems, Caleb, and Held, William and Pariani, Aryan J. and Morstatter, Fred and Yang, Diyi},
  booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
  year = "2023",
  month = jul,
  address = "Toronto, Canada",
  publisher = "Association for Computational Linguistics",
  abbr={ACL}
}

@inproceedings{ziems-etal-2022-positive-frames,
    bibtex_show={true},
    title = "Inducing Positive Perspectives with Text Reframing",
    author = "Ziems, Caleb  and
      Li, Minzhi  and
      Zhang, Anthony  and
      Yang, Diyi",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.257",
    pages = "3682--3700",
    abstract = "Sentiment transfer is one popular example of a text style transfer task, where the goal is to reverse the sentiment polarity of a text. With a sentiment reversal comes also a reversal in meaning. We introduce a different but related task called positive reframing in which we neutralize a negative point of view and generate a more positive perspective for the author without contradicting the original meaning. Our insistence on meaning preservation makes positive reframing a challenging and semantically rich task. To facilitate rapid progress, we introduce a large-scale benchmark, Positive Psychology Frames, with 8,349 sentence pairs and 12,755 structured annotations to explain positive reframing in terms of six theoretically-motivated reframing strategies. Then we evaluate a set of state-of-the-art text style transfer models, and conclude by discussing key challenges and directions for future work.",
    abbr={ACL},
    html={https://aclanthology.org/2022.acl-long.257},
    code={https://github.com/SALT-NLP/positive-frames},
    preview={positive_reframing.png},
    slides={slides/positive_reframing.pdf},
    note={<i class="fas fa-award"></i> <b>Outstanding Paper</b>},
}

@inproceedings{ziems-etal-2022-mic,
    bibtex_show={true},
    title = "The Moral Integrity Corpus: A Benchmark for Ethical Dialogue Systems",
    author = "Ziems, Caleb  and
      Yu, Jane  and
      Wang, Yi-Chia  and
      Halevy, Alon  and
      Yang, Diyi",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.261",
    pages = "3755--3773",
    abstract = "Conversational agents have come increasingly closer to human competence in open-domain dialogue settings; however, such models can reflect insensitive, hurtful, or entirely incoherent viewpoints that erode a user{'}s trust in the moral integrity of the system. Moral deviations are difficult to mitigate because moral judgments are not universal, and there may be multiple competing judgments that apply to a situation simultaneously. In this work, we introduce a new resource, not to authoritatively resolve moral ambiguities, but instead to facilitate systematic understanding of the intuitions, values and moral judgments reflected in the utterances of dialogue systems. The Moral Integrity Corpus, MIC, is such a resource, which captures the moral assumptions of 38k prompt-reply pairs, using 99k distinct Rules of Thumb (RoTs). Each RoT reflects a particular moral conviction that can explain why a chatbot{'}s reply may appear acceptable or problematic. We further organize RoTs with a set of 9 moral and social attributes and benchmark performance for attribute classification. Most importantly, we show that current neural language models can automatically generate new RoTs that reasonably describe previously unseen interactions, but they still struggle with certain scenarios. Our findings suggest that MIC will be a useful resource for understanding and language models{'} implicit moral assumptions and flexibly benchmarking the integrity of conversational agents.",
    abbr={ACL},
    slides={slides/mic.pdf},
    html={https://aclanthology.org/2022.acl-long.261/},
    code={https://github.com/SALT-NLP/mic},
  altmetric={true},
    preview={mic.png}
}

@inproceedings{ziems-etal-2022-value,
    bibtex_show={true},
    title = "{VALUE}: {U}nderstanding Dialect Disparity in {NLU}",
    author = "Ziems, Caleb  and
      Chen, Jiaao  and
      Harris, Camille  and
      Anderson, Jessica  and
      Yang, Diyi",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.258",
    pages = "3701--3720",
    abstract = "English Natural Language Understanding (NLU) systems have achieved great performances and even outperformed humans on benchmarks like GLUE and SuperGLUE. However, these benchmarks contain only textbook Standard American English (SAE). Other dialects have been largely overlooked in the NLP community. This leads to biased and inequitable NLU systems that serve only a sub-population of speakers. To understand disparities in current models and to facilitate more dialect-competent NLU systems, we introduce the VernAcular Language Understanding Evaluation (VALUE) benchmark, a challenging variant of GLUE that we created with a set of lexical and morphosyntactic transformation rules. In this initial release (V.1), we construct rules for 11 features of African American Vernacular English (AAVE), and we recruit fluent AAVE speakers to validate each feature transformation via linguistic acceptability judgments in a participatory design manner. Experiments show that these new dialectal features can lead to a drop in model performance.",
    abbr={ACL},
    code={https://github.com/SALT-NLP/value},
    preview={value.png},
    html={https://aclanthology.org/2022.acl-long.258/},
    slides={slides/value.pdf},
  altmetric={true}
}


@inproceedings{elsherief-2021-latent-hatred,
 bibtex_show={true},
 title = "Latent Hatred: A Benchmark for Understanding Implicit Hate Speech",
    author = "ElSherief, Mai  and
      Ziems, Caleb  and
      Muchlinski, David  and
      Anupindi, Vaishnavi  and
      Seybolt, Jordyn  and
      De Choudhury, Munmun  and
      Yang, Diyi",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.29",
    pages = "345--363",
    abstract = "Hate speech has grown significantly on social media, causing serious consequences for victims of all demographics. Despite much attention being paid to characterize and detect discriminatory speech, most work has focused on explicit or overt hate speech, failing to address a more pervasive form based on coded or indirect language. To fill this gap, this work introduces a theoretically-justified taxonomy of implicit hate speech and a benchmark corpus with fine-grained labels for each message and its implication. We present systematic analyses of our dataset using contemporary baselines to detect and explain implicit hate speech, and we discuss key features that challenge existing models. This dataset will continue to serve as a useful benchmark for understanding this multifaceted issue.",
 abbr={EMNLP},
 code={https://github.com/SALT-NLP/implicit-hate},
  altmetric={true},
  html={https://aclanthology.org/2021.emnlp-main.29/},
  slides={slides/implicit_hate.pdf},
 preview={implicit_hate.png}
}

@inproceedings{ziems-yang-2021-protect-serve,
 bibtex_show={true},
 title = "To Protect and To Serve? Analyzing Entity-Centric Framing of Police Violence",
    author = "Ziems, Caleb  and
      Yang, Diyi",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.82",
    pages = "957--976",
    abstract = "Framing has significant but subtle effects on public opinion and policy. We propose an NLP framework to measure entity-centric frames. We use it to understand media coverage on police violence in the United States in a new Police Violence Frames Corpus of 82k news articles spanning 7k police killings. Our work uncovers more than a dozen framing devices and reveals significant differences in the way liberal and conservative news sources frame both the issue of police violence and the entities involved. Conservative sources emphasize when the victim is armed or attacking an officer and are more likely to mention the victim{'}s criminal record. Liberal sources focus more on the underlying systemic injustice, highlighting the victim{'}s race and that they were unarmed. We discover temporary spikes in these injustice frames near high-profile shooting events, and finally, we show protest volume correlates with and precedes media framing decisions.",
 abbr={EMNLP},
 html={https://aclanthology.org/2021.findings-emnlp.82/},
 code={https://github.com/SALT-NLP/framing-police-violence},
 slides={slides/police_violence.pdf},
 year = {2021},
  altmetric={true},
 preview={police_violence.png}
}

@inproceedings{he2021yearlong,
  bibtex_show={true},
  title={Racism is a Virus: Anti-Asian Hate and Counterhate in Social Media during the COVID-19 Crisis},
  author={He, Bing and Ziems, Caleb and Soni, Sandeep and Ramakrishnan, Naren and Yang, Diyi and Kumar, Srijan},
  booktitle={2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
  year={2021},
  abbr={ASONAM},
  website={http://claws.cc.gatech.edu/covid},
  altmetric={true},
  arxiv={2005.12423},
  abstract="The spread of COVID-19 has sparked racism and hate on social media targeted towards Asian communities. However, little is known about how racial hate spreads during a pandemic and the role of counterspeech in mitigating this spread. In this work, we study the evolution and spread of anti-Asian hate speech through the lens of Twitter. We create COVID-HATE, the largest dataset of anti-Asian hate and counterspeech spanning 14 months, containing over 206 million tweets, and a social network with over 127 million nodes. By creating a novel hand-labeled dataset of 3,355 tweets, we train a text classifier to identify hate and counterspeech tweets that achieves an average macro-F1 score of 0.832. Using this dataset, we conduct longitudinal analysis of tweets and users. Analysis of the social network reveals that hateful and counterspeech users interact and engage extensively with one another, instead of living in isolated polarized communities. We find that nodes were highly likely to become hateful after being exposed to hateful content. Notably, counterspeech messages may discourage users from turning hateful, potentially suggesting a solution to curb hate on web and social media platforms.",
  preview={racism_virus.png}
}

@inproceedings{ziems2020aggressive,
  bibtex_show={true},
  title={Aggressive, Repetitive, Intentional, Visible, and Imbalanced: Refining Representations for Cyberbullying Classification},
  author={Ziems, Caleb and Vigfusson, Ymir and Morstatter, Fred},
  booktitle={Proceedings of the International AAAI Conference on Web and Social Media},
  volume={14},
  pages={808--819},
  abbr={ICWSM},
  year={2020},
  altmetric={true},
  arxiv={2004.01820},
  slides={slides/cyberbullying-representations-slides.pdf},
  code={https://github.com/cjziems/cyberbullying-representations},
  note={<i class="fas fa-award"></i> <b>Best Paper Honorable Mention</b>}
}
